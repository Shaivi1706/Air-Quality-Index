# -*- coding: utf-8 -*-
"""O3_SIH_Shaivi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N7KOC6Q4Dvik4u73Wj4HeV7LLFaXM-nK
"""

!pip install catboost

import zipfile
import os

zip_path = '/content/SIH_Data_PS-10.zip'
extract_path = '/content/SIH-Data'  # target directory

os.makedirs(extract_path, exist_ok=True)
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)
print("Extraction completed.")

# ===== FIXED PIPELINE FOR O3 AND NO2 SEPARATE MODELS =====
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import lightgbm as lgb
from catboost import CatBoostRegressor
from sklearn.utils import shuffle

# ---------------- 1. Load and preprocess ----------------
df = pd.read_csv('/content/SIH-Data/Data_SIH_2025/site_7_train_data.csv')

# Drop satellite columns with high missingness
cols_to_drop = [col for col in df.columns if 'satellite' in col]
df = df.drop(columns=cols_to_drop)
df.head(10)

df.info()

# Combine into datetime and extract date/hour
df['datetime'] = pd.to_datetime(df[['year','month','day','hour']])
df['date'] = df['datetime'].dt.date
df['hour'] = df['datetime'].dt.hour
df = df.drop(columns=['year','month','day'])
df.head(10)

df = df.sort_values('datetime').reset_index(drop=True)

# ---------------- 2. Feature Engineering ----------------
# Cyclic hour
df['hour_sin'] = np.sin(2*np.pi*df['hour']/24)
df['hour_cos'] = np.cos(2*np.pi*df['hour']/24)

# Rolling stats (24h) for forecasts and meteorology
forecast_cols = ['O3_forecast','NO2_forecast','T_forecast','q_forecast','u_forecast','v_forecast','w_forecast']
for col in forecast_cols:
    df[f'{col}_roll_mean_24'] = df[col].rolling(24,min_periods=1).mean()
    df[f'{col}_roll_std_24'] = df[col].rolling(24,min_periods=1).std().fillna(0)

# Lags for O3 and NO2 (shifted properly)
for lag in [1,24,48]:
    df[f'O3_lag_{lag}'] = df['O3_target'].shift(lag)
    df[f'NO2_lag_{lag}'] = df['NO2_target'].shift(lag)
df['O3_roll24_mean'] = df['O3_target'].rolling(24).mean().shift(1)
df['NO2_roll24_mean'] = df['NO2_target'].rolling(24).mean().shift(1)

# Drop rows with NaNs due to lags
df = df.dropna().reset_index(drop=True)

df.info()

# ---------------- 3. Train/Test Split ----------------
split_date = df['date'].quantile(0.75)  # 75% train, 25% test
train_df = df[df['date'] <= split_date].copy()
test_df  = df[df['date'] > split_date].copy()

# Features
feature_cols = [c for c in df.columns if c not in ['datetime','date','O3_target','NO2_target']]

X_train = train_df[feature_cols]
X_test  = test_df[feature_cols]

y_train_o3 = train_df['O3_target']
y_test_o3  = test_df['O3_target']
y_train_no2 = train_df['NO2_target']
y_test_no2  = test_df['NO2_target']

# ---------------- 4. Scaling (FIT ON TRAIN ONLY) ----------------
num_cols = X_train.select_dtypes(include=np.number).columns.tolist()
exclude_cols = ['hour']  # Keep hour unscaled if desired
num_cols = [c for c in num_cols if c not in exclude_cols]

scaler = StandardScaler()
X_train[num_cols] = scaler.fit_transform(X_train[num_cols])
X_test[num_cols] = scaler.transform(X_test[num_cols])

# ---------------- 5. LightGBM Models ----------------
lgb_params = {
    'objective':'regression',
    'metric':'rmse',
    'learning_rate':0.05,
    'num_leaves':31,
    'n_estimators':1000,
    'seed':42,
    'n_jobs':-1
}

# O3
print("Training LightGBM O3 model...")
model_lgb_o3 = lgb.LGBMRegressor(**lgb_params)
model_lgb_o3.fit(X_train, y_train_o3,
                 eval_set=[(X_test,y_test_o3)],
                 callbacks=[lgb.early_stopping(stopping_rounds=50)])
o3_pred_lgb = model_lgb_o3.predict(X_test)
print(f"LightGBM O3 RMSE: {np.sqrt(mean_squared_error(y_test_o3, o3_pred_lgb)):.4f}")
print(f"LightGBM O3 R²: {r2_score(y_test_o3, o3_pred_lgb):.4f}\n")

# NO2
print("Training LightGBM NO2 model...")
model_lgb_no2 = lgb.LGBMRegressor(**lgb_params)
model_lgb_no2.fit(X_train, y_train_no2,
                  eval_set=[(X_test,y_test_no2)],
                  callbacks=[lgb.early_stopping(stopping_rounds=50)])
no2_pred_lgb = model_lgb_no2.predict(X_test)
print(f"LightGBM NO2 RMSE: {np.sqrt(mean_squared_error(y_test_no2, no2_pred_lgb)):.4f}")
print(f"LightGBM NO2 R²: {r2_score(y_test_no2, no2_pred_lgb):.4f}\n")

# ---------------- 6. CatBoost Models ----------------
cat_params = {
    'iterations':1000,
    'learning_rate':0.05,
    'depth':6,
    'eval_metric':'RMSE',
    'random_seed':42,
    'verbose':0
}

# O3
print("Training CatBoost O3 model...")
model_cat_o3 = CatBoostRegressor(**cat_params)
model_cat_o3.fit(X_train, y_train_o3, eval_set=(X_test,y_test_o3), early_stopping_rounds=50)
o3_pred_cat = model_cat_o3.predict(X_test)
print(f"CatBoost O3 RMSE: {np.sqrt(mean_squared_error(y_test_o3, o3_pred_cat)):.4f}")
print(f"CatBoost O3 R²: {r2_score(y_test_o3, o3_pred_cat):.4f}\n")

# NO2
print("Training CatBoost NO2 model...")
model_cat_no2 = CatBoostRegressor(**cat_params)
model_cat_no2.fit(X_train, y_train_no2, eval_set=(X_test,y_test_no2), early_stopping_rounds=50)
no2_pred_cat = model_cat_no2.predict(X_test)
print(f"CatBoost NO2 RMSE: {np.sqrt(mean_squared_error(y_test_no2, no2_pred_cat)):.4f}")
print(f"CatBoost NO2 R²: {r2_score(y_test_no2, no2_pred_cat):.4f}\n")

# ---------------- 7. Permutation Importance ----------------
def permutation_importance(model, X, y, model_name, top_n=10):
    base_rmse = np.sqrt(mean_squared_error(y, model.predict(X)))
    perm_imp = {}
    for col in X.columns:
        X_perm = X.copy()
        X_perm[col] = shuffle(X_perm[col].values, random_state=42)
        perm_rmse = np.sqrt(mean_squared_error(y, model.predict(X_perm)))
        perm_imp[col] = perm_rmse - base_rmse
    perm_imp = dict(sorted(perm_imp.items(), key=lambda x: x[1], reverse=True))
    print(f"\n{'='*60}")
    print(f"{model_name} - Top {top_n} Permutation Importances:")
    print(f"{'='*60}")
    for k,v in list(perm_imp.items())[:top_n]:
        print(f"{k:40s}: +{v:.4f} RMSE")
    return perm_imp

# Run for both pollutants
print("\n" + "="*60)
print("PERMUTATION IMPORTANCE ANALYSIS")
print("="*60)
perm_imp_o3 = permutation_importance(model_cat_o3, X_test, y_test_o3, "CatBoost O3")
perm_imp_no2 = permutation_importance(model_cat_no2, X_test, y_test_no2, "CatBoost NO2")

df.info()

# import joblib
# joblib.dump(model_cat_o3, "model_cat_o3.pkl")
# joblib.dump(model_cat_no2, "model_cat_no2.pkl")
